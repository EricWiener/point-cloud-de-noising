{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0a23a2d6909c68acaee8cdc174eaa8f4ab01509589aa59c1ab9b2bf57fe831546",
   "display_name": "Python 3.9.2 64-bit ('pcd-de-noising': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "a23a2d6909c68acaee8cdc174eaa8f4ab01509589aa59c1ab9b2bf57fe831546"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from model.weathernet import WeatherNet\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from pcd_dataset import PCDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorboard logger\n",
    "# You can start locally using `tensorboard --logdir ./src/pcd_de_noising/tb_logs`\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"WeatherNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WeatherNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASET_PATH = \"/Users/ericwiener/repositories/point-cloud-de-noising/data\"\n",
    "# DATASET_PATH = (\n",
    "#     \"/home/elliot/Desktop/cnn_denoising_dataset/train\"  # TODO: use train_road?\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 3 files\n"
     ]
    }
   ],
   "source": [
    "dataset = PCDDataset(DATASET_PATH, recursive=True)\n",
    "print(f\"Found {len(dataset)} files\")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "source": [
    "# Overfit"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    overfit_batches=2,\n",
    "    progress_bar_refresh_rate=30,\n",
    "    max_epochs=30,\n",
    "    flush_logs_every_n_steps=1,\n",
    "    log_every_n_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/ericwiener/anaconda3/envs/pcd-de-noising/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | lila1      | LiLaBlock | 49.3 K\n",
      "1 | lila2      | LiLaBlock | 804 K \n",
      "2 | lila3      | LiLaBlock | 2.2 M \n",
      "3 | lila4      | LiLaBlock | 4.2 M \n",
      "4 | dropout    | Dropout2d | 0     \n",
      "5 | lila5      | LiLaBlock | 2.0 M \n",
      "6 | classifier | Conv2d    | 387   \n",
      "-----------------------------------------\n",
      "9.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.3 M     Total params\n",
      "37.257    Total estimated model params size (MB)\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] /Users/ericwiener/anaconda3/envs/pcd-de-noising/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: You requested to overfit but enabled training dataloader shuffling. We are turning it off for you.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/ericwiener/anaconda3/envs/pcd-de-noising/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 18:   0%|          | 0/1 [00:07<?, ?it/s, loss=0.762, v_num=10]\n",
      "/Users/ericwiener/anaconda3/envs/pcd-de-noising/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "trainer.fit(model, loader)"
   ]
  },
  {
   "source": [
    "# Train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    max_epochs=30,\n",
    "    flush_logs_every_n_steps=1,\n",
    "    log_every_n_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/ericwiener/anaconda3/envs/pcd-de-noising/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | lila1      | LiLaBlock | 49.3 K\n",
      "1 | lila2      | LiLaBlock | 804 K \n",
      "2 | lila3      | LiLaBlock | 2.2 M \n",
      "3 | lila4      | LiLaBlock | 4.2 M \n",
      "4 | dropout    | Dropout2d | 0     \n",
      "5 | lila5      | LiLaBlock | 2.0 M \n",
      "6 | classifier | Conv2d    | 387   \n",
      "-----------------------------------------\n",
      "9.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.3 M     Total params\n",
      "37.257    Total estimated model params size (MB)\n",
      "Epoch 29: 100%|██████████| 1/1 [00:06<00:00,  6.87s/it, loss=0.028, v_num=11]"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "trainer.fit(model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}