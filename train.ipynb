{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0a23a2d6909c68acaee8cdc174eaa8f4ab01509589aa59c1ab9b2bf57fe831546",
   "display_name": "Python 3.9.2 64-bit ('pcd-de-noising': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "a23a2d6909c68acaee8cdc174eaa8f4ab01509589aa59c1ab9b2bf57fe831546"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from src.pcd_de_noising import WeatherNet\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from src.pcd_de_noising import PCDDataset, PointCloudDataModule\n",
    "import os"
   ]
  },
  {
   "source": [
    "# Configuration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_GPUS = 1\n",
    "DATASET_PATH = \"./data\"\n",
    "# DATASET_PATH = (\n",
    "#     \"/home/elliot/Desktop/cnn_denoising_dataset/train\"  # TODO: use train_road?\n",
    "# )"
   ]
  },
  {
   "source": [
    "# Logging"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorboard logger\n",
    "# You can start locally using `tensorboard --logdir ./src/pcd_de_noising/tb_logs`\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"WeatherNet\")"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Create new model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WeatherNet()"
   ]
  },
  {
   "source": [
    "### Load from checkpoint"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "WeatherNet(\n",
       "  (lila1): LiLaBlock(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(2, 96, kernel_size=(7, 3), stride=(1, 1), padding=(2, 0), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): BasicConv2d(\n",
       "      (conv): Conv2d(2, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3): BasicConv2d(\n",
       "      (conv): Conv2d(2, 96, kernel_size=(3, 7), stride=(1, 1), padding=(0, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch4): BasicConv2d(\n",
       "      (conv): Conv2d(2, 96, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv): BasicConv2d(\n",
       "      (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (lila2): LiLaBlock(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(96, 128, kernel_size=(7, 3), stride=(1, 1), padding=(2, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): BasicConv2d(\n",
       "      (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 128, kernel_size=(3, 7), stride=(1, 1), padding=(0, 2), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch4): BasicConv2d(\n",
       "      (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (lila3): LiLaBlock(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(7, 3), stride=(1, 1), padding=(2, 0), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 7), stride=(1, 1), padding=(0, 2), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv): BasicConv2d(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (lila4): LiLaBlock(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(7, 3), stride=(1, 1), padding=(2, 0), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): BasicConv2d(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3): BasicConv2d(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 7), stride=(1, 1), padding=(0, 2), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch4): BasicConv2d(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv): BasicConv2d(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
       "  (lila5): LiLaBlock(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(7, 3), stride=(1, 1), padding=(2, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 7), stride=(1, 1), padding=(0, 2), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch4): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Conv2d(128, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.load_from_checkpoint('./tb_logs/WeatherNet/version_1/checkpoints/epoch=4-step=4.ckpt')"
   ]
  },
  {
   "source": [
    "# Prepare Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = PointCloudDataModule(os.path.join(DATASET_PATH, \"train\"), os.path.join(DATASET_PATH, \"val\"))"
   ]
  },
  {
   "source": [
    "# Overfit"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    overfit_batches=2,\n",
    "    progress_bar_refresh_rate=30,\n",
    "    max_epochs=30,\n",
    "    flush_logs_every_n_steps=1,\n",
    "    log_every_n_steps=1,\n",
    "    gpus=NUMBER_GPUS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | lila1      | LiLaBlock | 49.3 K\n",
      "1 | lila2      | LiLaBlock | 804 K \n",
      "2 | lila3      | LiLaBlock | 2.2 M \n",
      "3 | lila4      | LiLaBlock | 4.2 M \n",
      "4 | dropout    | Dropout2d | 0     \n",
      "5 | lila5      | LiLaBlock | 2.0 M \n",
      "6 | classifier | Conv2d    | 387   \n",
      "-----------------------------------------\n",
      "9.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.3 M     Total params\n",
      "37.257    Total estimated model params size (MB)\n",
      "Train found 3 files\n",
      "Train found 3 files\n",
      "Train found 3 files\n",
      "Epoch 10: 100%|██████████| 2/2 [00:11<00:00,  5.79s/it]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 2/2 [00:19<00:00,  9.76s/it, loss=2.37, v_num=1]\n",
      "Epoch 11: 100%|██████████| 2/2 [00:11<00:00,  5.89s/it, loss=2.37, v_num=1]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 2/2 [00:20<00:00, 10.15s/it, loss=2.23, v_num=1]\n",
      "Epoch 12: 100%|██████████| 2/2 [00:11<00:00,  5.94s/it, loss=2.23, v_num=1]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 2/2 [00:20<00:00, 10.29s/it, loss=2.06, v_num=1]\n",
      "Epoch 13: 100%|██████████| 2/2 [00:12<00:00,  6.02s/it, loss=2.06, v_num=1]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 2/2 [00:20<00:00, 10.23s/it, loss=1.92, v_num=1]\n",
      "Epoch 14: 100%|██████████| 2/2 [00:11<00:00,  5.81s/it, loss=1.92, v_num=1]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 2/2 [00:19<00:00,  9.84s/it, loss=1.8, v_num=1] \n",
      "Epoch 15: 100%|██████████| 2/2 [00:11<00:00,  5.82s/it, loss=1.8, v_num=1]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 2/2 [00:19<00:00,  9.77s/it, loss=1.68, v_num=1]\n",
      "Epoch 16:   0%|          | 0/2 [00:00<?, ?it/s, loss=1.68, v_num=1]"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "source": [
    "# Train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    max_epochs=30,\n",
    "    flush_logs_every_n_steps=1,\n",
    "    log_every_n_steps=1,\n",
    "    gpus=NUMBER_GPUS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/ericwiener/anaconda3/envs/pcd-de-noising/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | lila1      | LiLaBlock | 49.3 K\n",
      "1 | lila2      | LiLaBlock | 804 K \n",
      "2 | lila3      | LiLaBlock | 2.2 M \n",
      "3 | lila4      | LiLaBlock | 4.2 M \n",
      "4 | dropout    | Dropout2d | 0     \n",
      "5 | lila5      | LiLaBlock | 2.0 M \n",
      "6 | classifier | Conv2d    | 387   \n",
      "-----------------------------------------\n",
      "9.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.3 M     Total params\n",
      "37.257    Total estimated model params size (MB)\n",
      "Epoch 29: 100%|██████████| 1/1 [00:06<00:00,  6.87s/it, loss=0.028, v_num=11]"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  }
 ]
}
